---
title: "Milestone 7_Analysis_Nellaphen"
output: html_notebook
editor_options: 
  chunk_output_type: console
---

#install packages
```{r}
install.packages("tidyverse")
install.packages("emmeans")
install.packages("performance")
install.packages("see")
install.packages("patchwork")
install.packages("lmerTest")
```

#load packages
```{r}
library(tidyverse)
library(emmeans)
library(performance)
library(see)
library(patchwork)
library(lmerTest)
```

#Class Data imported

```{r}
nellaphen_data = read_csv("nellaphen_data_cleaned.csv")
```

#Inspect data
```{r}
#How many rows and columns are in your file?
nrow(nellaphen_data)

ncol(nellaphen_data)
#10402 rows and 42 columns

#How many unique “subjects” does this file have? How many trials did each subject do in this experiment?

nellaphen_data %>%
  pull(sona_id) %>% unique() %>% length()

nellaphen_data %>% group_by(sona_id) %>% count()
# 17 participants, each subject completed around 600 trials

#Which columns contain your independent variable(s) and dependent variable(s)?

# independent variable: type, relatedness, alliterative 
#dependent variables: rt (response time)

#How many levels do your independent variables have?
#type: 2 (shared / direct / novel)
#relatedness: 2 (related / unrelated) 
#alliterative: 2 (alliterative [1] / non-alliterative [0])

```


# Basic descriptives
```{r}
#What is the average accuracy in your experiment? What is the standard deviation of the accuracy?
attention_trial_data = nellaphen_data %>%
  filter(typeoftrial == 'attention')

attention_trial_data$revised_correct = as.numeric(attention_trial_data$revised_correct)

mean_experiment_acc = attention_trial_data %>%
  summarize(mean_accuracy = mean(revised_correct), sd_accuracy = sd(revised_correct))

#Calculate the mean accuracy for each subject
subject_acc = attention_trial_data %>%
  group_by(sona_id) %>%
  summarize(mean_accuracy = mean(revised_correct))

```

```{r}
#What does the histogram of reaction times look like in your experiment for the critical trials?

association_trial_data = nellaphen_data %>%
  filter(typeoftrial == 'association')

target_trial_data = nellaphen_data %>%
  filter(typeoftrial == 'target')

ggplot(data = target_trial_data)+
  geom_histogram(mapping = aes(x = as.numeric(rt)))


```

# Reaction Time by Subject/Condition

```{r}
#Calculate the average reaction time for each subject in each condition in your experiment.

# This is not correct below -- but working on it

subject_condition_rt = nellaphen_data %>%
  filter(typeoftrial == 'target') %>%
  mutate(rt = as.numeric(rt)) %>%
  group_by(sona_id, type, relatedness) %>%
  summarize(mean_response_rt = mean(rt))

```

# Bar Plots for IVs

```{r}
## prime type plot
prime_rt = nellaphen_data %>%
  filter(typeoftrial == 'target') %>%
  mutate(rt = as.numeric(rt)) %>%
  group_by(type, relatedness) %>%
  summarize(mean_response_rt = mean(rt))

ggplot(data = prime_rt) +
  geom_col(mapping = aes(x = type, y = mean_response_rt, fill = relatedness), position = "dodge") +
  theme_bw()+
  labs(title = "plot of RTs", x = "Prime", y = "Mean RT (ms)")+
  scale_fill_grey()

## alliteration plot
alliteration_rt = nellaphen_data %>%
  filter(typeoftrial == 'target', type == 'shared', relatedness == 'related') %>%
  mutate(rt = as.numeric(rt), condition = as.character(condition)) %>%
  group_by(condition) %>%
  summarize(mean_response_rt = mean(rt))

ggplot(data = alliteration_rt) +
  geom_col(mapping = aes(x = condition, y = mean_response_rt), position = "dodge") +
  theme_bw()+
  labs(title = "plot of alliteration RTs", x = "Condition", y = "Mean RT (ms)")+
  scale_fill_grey()
```
We seem to see little difference in rt for direct and shared primes, although both result in faster rts than novel words. Additionally, related words seem to result in faster rts than unrelated words.

For our alliteration IV, we see that participants in condition 2 (alliterative primes) have a slightly faster average rt than those in condition 1 (non-alliterative primes).

# Inferential Statistics
