---
title: "Milestone 7_Analysis_Nellaphen"
output: html_notebook
editor_options: 
  chunk_output_type: console
---

#install packages
```{r}
#install.packages("tidyverse")
#install.packages("emmeans")
#install.packages("performance")
#install.packages("see")
#install.packages("patchwork")
#install.packages("lmerTest")
```

#load packages
```{r}
library(tidyverse)
library(emmeans)
library(performance)
library(see)
library(patchwork)
library(lmerTest)
```

#Class Data imported

```{r}
initial_sona_data = read_csv("sona_data_nellaphen.csv") %>% 
  select(-sona_id)

initial_prolific_data1 = read_csv("prolific_data_nellaphen_1.csv")

initial_prolific_data2 = read_csv("prolific_data_nellaphen_2.csv")

nellaphen_data = rbind(initial_sona_data,initial_prolific_data1,
                       initial_prolific_data2) %>%
mutate(condition = ifelse(condition == 1, "non-alliterative", "alliterative"), rt = as.numeric(rt), condition = as.character(condition), revised_correct = as.numeric(correct))
```

```{r}
incomplete_IDs = initial_data %>%
  filter(typeoftrial == 'demo_age_gender_edu') %>% pull (ID)

low_acc_IDs = initial_data %>%
  filter(typeoftrial == 'attention') %>%
  group_by(ID) %>%
  summarize(id_mean_correct = mean(revised_correct)) %>%
  filter(id_mean_correct < 0.75) %>% pull (ID)

nellaphen_data = initial_data %>%
  filter(!ID %in% low_acc_IDs) %>%
  filter(ID %in% incomplete_IDs)
```


# Inspect data

How many rows and columns are in your file?
```{r}

nrow(nellaphen_data)

ncol(nellaphen_data)

```
10402 rows and 42 columns

How many unique “subjects” does this file have? How many trials did each subject do in this experiment?

```{r}
nellaphen_data %>%
  pull(ID) %>% unique() %>% length()

nellaphen_data %>% group_by(ID) %>% count()
```
17 participants, each subject completed around 600 trials

Which columns contain your independent variable(s) and dependent variable(s)?

Independent variable: type, relatedness, alliterative 
Dependent variables: rt (response time)

How many levels do your independent variables have?

type: 2 (shared / direct / novel)
relatedness: 2 (related / unrelated) 
alliterative: 2 (alliterative [1] / non-alliterative [0])


# Basic Descriptives

What is the average accuracy in your experiment? What is the standard deviation of the accuracy?
```{r}

attention_trial_data = nellaphen_data %>%
  filter(typeoftrial == 'attention')
  
attention_trial_data$revised_correct = as.numeric(attention_trial_data$revised_correct)

mean_experiment_acc = attention_trial_data %>%
  summarize(mean_accuracy = mean(revised_correct), sd_accuracy = sd(revised_correct))

```

Calculate the mean accuracy for each subject:

```{r}
subject_acc = attention_trial_data %>%
  group_by(ID) %>%
  summarize(mean_accuracy = mean(revised_correct))
```


What does the histogram of reaction times look like in your experiment for the critical trials?
```{r}

association_trial_data = nellaphen_data %>%
  filter(typeoftrial == 'association')

target_trial_data = nellaphen_data %>%
  filter(typeoftrial == 'target', rt > 200, rt < 1500)

ggplot(data = target_trial_data)+
  geom_histogram(mapping = aes(x = as.numeric(rt)))

```

Calculate the average reaction time for each subject in each condition in your experiment.
```{r}

subject_condition_rt = nellaphen_data %>%
  filter(typeoftrial == 'target', rt > 200, rt < 1500) %>%
  group_by(ID, type, relatedness) %>%
  summarize(mean_response_rt = mean(rt))

```

#Bar Plots for IVs:

```{r}
## prime type plot
prime_rt = nellaphen_data %>%
  filter(typeoftrial == 'target', rt > 200, rt < 1500) %>%
  group_by(type, relatedness) %>%
  summarize(mean_response_rt = mean(rt))

ggplot(data = prime_rt) +
  geom_col(mapping = aes(x = type, y = mean_response_rt, fill = relatedness), position = "dodge") +
  theme_bw()+
  labs(title = "plot of RTs", x = "Prime", y = "Mean RT (ms)")+
  scale_fill_grey()

## alliteration plot
condition_comparison = nellaphen_data %>%
  filter(typeoftrial == "target", type == "shared", rt > 200, rt < 1500) %>%
  group_by(relatedness, condition) %>%
  summarize(mean_rt = mean(rt), sd_rt = sd(rt))

ggplot(data = condition_comparison, mapping = aes(x = condition, y = mean_rt, fill = relatedness))+
  geom_col(position = "dodge") +
  geom_errorbar(aes(ymin = mean_rt-sd_rt,
                    ymax = mean_rt+sd_rt),
                width = 0.25,
                position = position_dodge(width=0.9)) +
  labs(title = "Comparison between alliteration and non-alliteration", x = "Condition", y = "Mean RT (ms)")
```

We seem to see little difference in rt for direct and shared primes, although both result in faster rts than novel words. Additionally, related words seem to result in faster rts than unrelated words.

For our alliteration IV, we see that participants in condition 2 (alliterative primes) have a slightly faster average rt than those in condition 1 (non-alliterative primes).

# Inferential Statistics

Our first research aim is to replicate the findings of Savic et al. surrounding prime words and learned word associations.

Our second aim is to pursue the question of if alliterative prime words enhances learned prime psudoword and target word associations.

```{r}
## alliterative condition comparison
condition_comparison_id = nellaphen_data %>%
  filter(typeoftrial == "target", type == "shared", rt > 200, rt < 1500) %>%
  group_by(ID, relatedness, condition) %>%
  summarize(mean_rt = mean(rt),)
comparison = lmer(data = condition_comparison_id, mean_rt ~ relatedness * condition + (1|ID))

summary(comparison)
car::Anova(comparison)
performance::check_model(comparison)
emmeans::emmeans(comparison,
                 pairwise ~ relatedness | condition,
                 adjust="tukey")
```


